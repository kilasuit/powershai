---
external help file: powershai-help.xml
Module Name: powershai
online version:
schema: 2.0.0
---

# New-PowershaiParameters

## SYNOPSIS
Creates a new object that represents the parameters of a PowershaiChat.

## SYNTAX

```
New-PowershaiParameters [[-stream] <Object>] [[-Json] <Boolean>] [[-model] <String>] [[-MaxTokens] <Int32>]
 [[-ShowFullSend] <Boolean>] [[-ShowTokenStats] <Object>] [[-MaxInteractions] <Object>]
 [[-MaxSeqErrors] <Object>] [[-MaxContextSize] <Object>] [[-ContextFormatterFunc] <Object>]
 [[-ContextFormatterParams] <Object>] [[-ShowArgs] <Object>] [[-PrintToolsResults] <Object>]
 [[-SystemMessageFixed] <Object>] [[-RawParams] <Object>] [[-ContextFormat] <Object>] [<CommonParameters>]
```

## DESCRIPTION
Creates a default object containing all possible parameters that can be used in the chat!
The user can use get-help New-PowershaiParameters to get the documentation of the parameters.

## EXAMPLES

### Example 1
```powershell
PS C:\> {{ Add example code here }}
```

{{ Add example description here }}

## PARAMETERS

### -stream
When true, uses stream mode, that is, messages are shown as the model produces them.

```yaml
Type: Object
Parameter Sets: (All)
Aliases:

Required: False
Position: 1
Default value: True
Accept pipeline input: False
Accept wildcard characters: False
```

### -Json
Enables JSON mode.
In this mode, the model is forced to return a response in JSON.
 
When activated, messages generated via stream are not displayed as they are produced, and only the final result is returned.

```yaml
Type: Boolean
Parameter Sets: (All)
Aliases:

Required: False
Position: 2
Default value: False
Accept pipeline input: False
Accept wildcard characters: False
```

### -model
Name of the model to be used  
If null, uses the model defined with Set-AiDefaultModel.

```yaml
Type: String
Parameter Sets: (All)
Aliases:

Required: False
Position: 3
Default value: None
Accept pipeline input: False
Accept wildcard characters: False
```

### -MaxTokens
Maximum number of tokens to be returned by the model.

```yaml
Type: Int32
Parameter Sets: (All)
Aliases:

Required: False
Position: 4
Default value: 2048
Accept pipeline input: False
Accept wildcard characters: False
```

### -ShowFullSend
Prints the entire prompt that is being sent to the LLM.

```yaml
Type: Boolean
Parameter Sets: (All)
Aliases:

Required: False
Position: 5
Default value: False
Accept pipeline input: False
Accept wildcard characters: False
```

### -ShowTokenStats
At the end of each message, displays the consumption statistics, in tokens, returned by the API.

```yaml
Type: Object
Parameter Sets: (All)
Aliases:

Required: False
Position: 6
Default value: False
Accept pipeline input: False
Accept wildcard characters: False
```

### -MaxInteractions
Maximum number of interactions to be made at once. 
Each time a message is sent, the model executes 1 iteration (sends the message and receives a response).
 
If the model requests a function calling, the generated response will be sent back to the model.
This counts as another interaction.
 
This parameter controls the maximum number of interactions that can exist in each call.
This helps to prevent unexpected infinite loops.

```yaml
Type: Object
Parameter Sets: (All)
Aliases:

Required: False
Position: 7
Default value: 50
Accept pipeline input: False
Accept wildcard characters: False
```

### -MaxSeqErrors
Maximum number of sequential errors generated by Tool Calling.
 
When using tool calling, this parameter limits how many non-sequential tools that resulted in errors can be called.
 
The considered error is the exception thrown by the script or configured command.

```yaml
Type: Object
Parameter Sets: (All)
Aliases:

Required: False
Position: 8
Default value: 5
Accept pipeline input: False
Accept wildcard characters: False
```

### -MaxContextSize
Maximum context size, in characters. 
In the future, it will be in tokens. 
Controls the amount of messages in the current chat context.
When this number is exceeded, Powershai automatically clears the oldest messages.

```yaml
Type: Object
Parameter Sets: (All)
Aliases:

Required: False
Position: 9
Default value: 8192
Accept pipeline input: False
Accept wildcard characters: False
```

### -ContextFormatterFunc
Function used for formatting the objects passed via pipeline.

```yaml
Type: Object
Parameter Sets: (All)
Aliases:

Required: False
Position: 10
Default value: ConvertTo-PowershaiContextOutString
Accept pipeline input: False
Accept wildcard characters: False
```

### -ContextFormatterParams
Arguments to be passed to the ContextFormatterFunc.

```yaml
Type: Object
Parameter Sets: (All)
Aliases:

Required: False
Position: 11
Default value: None
Accept pipeline input: False
Accept wildcard characters: False
```

### -ShowArgs
If true, displays the arguments of the functions when Tool Calling is activated to execute some function.

```yaml
Type: Object
Parameter Sets: (All)
Aliases:

Required: False
Position: 12
Default value: True
Accept pipeline input: False
Accept wildcard characters: False
```

### -PrintToolsResults
Displays the results of the tools when they are executed by PowershAI in response to the model's tool calling.

```yaml
Type: Object
Parameter Sets: (All)
Aliases:

Required: False
Position: 13
Default value: False
Accept pipeline input: False
Accept wildcard characters: False
```

### -SystemMessageFixed
System Message that is guaranteed to be sent always, regardless of the chat history and cleanup!

```yaml
Type: Object
Parameter Sets: (All)
Aliases:

Required: False
Position: 14
Default value: None
Accept pipeline input: False
Accept wildcard characters: False
```

### -RawParams
Parameters to be passed directly to the API that invokes the model.
 
The provider must implement support for this.
 
To use it, you must know the implementation details of the provider and how its API works!

```yaml
Type: Object
Parameter Sets: (All)
Aliases:

Required: False
Position: 15
Default value: @{}
Accept pipeline input: False
Accept wildcard characters: False
```

### -ContextFormat
Controls the template used when injecting context data!
This parameter is a scriptblock that must return a string with the context to be injected into the prompt!
The parameters of the scriptblock are:
	FormattedObject 	- The object that represents the active chat, already formatted with the configured Formatter.
	CmdParams 			- The parameters passed to Send-PowershaAIChat.
It is the same object returned by GetMyParams.
	Chat 				- The chat in which the data is being sent.
If null, it will generate a default.
Check the cmdlet Send-PowershaiChat for details.

```yaml
Type: Object
Parameter Sets: (All)
Aliases:

Required: False
Position: 16
Default value: None
Accept pipeline input: False
Accept wildcard characters: False
```

### CommonParameters
This cmdlet supports the common parameters: -Debug, -ErrorAction, -ErrorVariable, -InformationAction, -InformationVariable, -OutVariable, -OutBuffer, -PipelineVariable, -Verbose, -WarningAction, and -WarningVariable. For more information, see [about_CommonParameters](http://go.microsoft.com/fwlink/?LinkID=113216).

## INPUTS

## OUTPUTS

## NOTES

## RELATED LINKS



_Automatically translated using PowershAI and AI._
